{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMwHG6jGezBw4IQeYc2xNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JNAbhishek27/DeID-Guard/blob/main/DeID_Guard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay8wBd2cV3l-"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y poppler-utils\n",
        "!pip install pytesseract pdf2image opencv-python PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import fitz  # PyMuPDF\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OF72Ed23V-1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PDF to image\n",
        "pages = convert_from_path(\"/content/sample_pii.pdf\", dpi=300)\n",
        "page = pages[0]   # First page only\n",
        "\n",
        "# Save as image for OCR\n",
        "page.save(\"page1.png\", \"PNG\")"
      ],
      "metadata": {
        "id": "q7aNMYCxWHK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img = cv2.imread(\"page1.png\")\n",
        "\n",
        "# Convert to gray for better OCR\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# OCR extraction\n",
        "text = pytesseract.image_to_string(gray)\n",
        "print(\"Extracted Text:\\n\", text)"
      ],
      "metadata": {
        "id": "flZTerxdWahB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yyWq0T7BWc3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "9Z-o9LLMWgyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load transformer-based spaCy model\n",
        "nlp = spacy.load(\"en_core_web_trf\")"
      ],
      "metadata": {
        "id": "CIgJ12QgWkS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Patient Name: Rahul Sharma\n",
        "DOB: 12/08/1995\n",
        "Phone: +91-9876543210\n",
        "Address: 123 MG Road, Bangalore\n",
        "Aadhaar: 1234-5678-9123\n",
        "Diagnosis: Type II Diabetes\n",
        "\"\"\"\n",
        "\n",
        "doc = nlp(sample_text)\n",
        "\n",
        "pii_entities = []\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ in [\"PERSON\", \"GPE\", \"ORG\", \"DATE\", \"CARDINAL\", \"MONEY\"]:\n",
        "        pii_entities.append((ent.text, ent.label_))\n",
        "\n",
        "# Regex rules for IDs / phone numbers\n",
        "regex_patterns = {\n",
        "    \"PHONE\": r\"\\+?\\d[\\d -]{8,12}\\d\",\n",
        "    \"AADHAAR\": r\"\\d{4}-\\d{4}-\\d{4}\",\n",
        "    \"EMAIL\": r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "}\n",
        "\n",
        "for label, pattern in regex_patterns.items():\n",
        "    matches = re.findall(pattern, sample_text)\n",
        "    for m in matches:\n",
        "        pii_entities.append((m, label))\n",
        "\n",
        "print(\"Detected PII:\", pii_entities)"
      ],
      "metadata": {
        "id": "lcxyc88XW-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_text(text):\n",
        "    doc = nlp(text)\n",
        "    redacted = text\n",
        "\n",
        "    # Replace NER-detected PII\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"PERSON\", \"GPE\", \"ORG\", \"DATE\", \"CARDINAL\", \"MONEY\"]:\n",
        "            redacted = redacted.replace(ent.text, \"[REDACTED]\")\n",
        "\n",
        "    # Replace regex PII\n",
        "    for label, pattern in regex_patterns.items():\n",
        "        redacted = re.sub(pattern, \"[REDACTED]\", redacted)\n",
        "\n",
        "    return redacted\n",
        "\n",
        "print(\"Original Text:\\n\", sample_text)\n",
        "print(\"\\nRedacted Text:\\n\", redact_text(sample_text))"
      ],
      "metadata": {
        "id": "Bb3bfiRIXBnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy PyMuPDF\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "teV2tkcxXFjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_trf\")"
      ],
      "metadata": {
        "id": "zrW6O-7sXKHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex_patterns = {\n",
        "    \"PHONE\": r\"\\+?\\d[\\d -]{8,12}\\d\",\n",
        "    \"AADHAAR\": r\"\\d{4}-\\d{4}-\\d{4}\",\n",
        "    \"EMAIL\": r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "}\n",
        "\n",
        "def detect_pii(text):\n",
        "    pii_entities = []\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"PERSON\", \"GPE\", \"ORG\", \"DATE\", \"CARDINAL\", \"MONEY\"]:\n",
        "            pii_entities.append(ent.text)\n",
        "\n",
        "    for label, pattern in regex_patterns.items():\n",
        "        matches = re.findall(pattern, text)\n",
        "        pii_entities.extend(matches)\n",
        "\n",
        "    return list(set(pii_entities))"
      ],
      "metadata": {
        "id": "QQHJQ1peXQhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_pdf(input_pdf, output_pdf):\n",
        "    doc = fitz.open(input_pdf)\n",
        "    for page in doc:\n",
        "        text = page.get_text()\n",
        "        pii_list = detect_pii(text)\n",
        "\n",
        "        for pii in pii_list:\n",
        "            areas = page.search_for(pii)\n",
        "            for area in areas:\n",
        "                page.add_redact_annot(area, fill=(0, 0, 0))\n",
        "        page.apply_redactions()\n",
        "    doc.save(output_pdf)\n",
        "    print(f\"Redacted PDF saved as: {output_pdf}\")\n",
        "\n",
        "# Run on your uploaded PDF\n",
        "redact_pdf(\"sample_pii.pdf\", \"redacted_sample.pdf\")"
      ],
      "metadata": {
        "id": "V1dmxIiKXStq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"redacted_sample.pdf\")"
      ],
      "metadata": {
        "id": "h7FrdfgHXUWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "pi1rzZqrXd_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load OpenCV face detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
      ],
      "metadata": {
        "id": "0r1VW34SXtlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_faces(image_path, output_path=\"face_redacted.png\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
        "\n",
        "    # Redact each face with a black box\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    # Show result\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(f\"Redacted image saved as {output_path}\")"
      ],
      "metadata": {
        "id": "Oha_y-eBXwRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_faces(\"Untitled design.jpg\")"
      ],
      "metadata": {
        "id": "e3sMnR6yXyd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyzbar opencv-python\n",
        "!apt-get install -y libzbar0\n",
        "!pip install pyzbar Pillow opencv-python"
      ],
      "metadata": {
        "id": "43n225ZiX-97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyzbar.pyzbar import decode\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def redact_qr_barcode(image_path, output_path=\"qr_redacted.png\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    barcodes = decode(Image.open(image_path))\n",
        "\n",
        "    for bc in barcodes:\n",
        "        (x, y, w, h) = bc.rect\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    # Show output\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(f\"Redacted QR/Barcode saved as {output_path}\")\n",
        "\n",
        "# Run on your uploaded file\n",
        "redact_qr_barcode(\"qr.png\")"
      ],
      "metadata": {
        "id": "lOrzjON-YGBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_signatures(image_path, output_path=\"signature_redacted.png\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold for ink regions (handwriting)\n",
        "    _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        # Heuristic: Signatures are usually small & wide\n",
        "        if 50 < w < 500 and 10 < h < 200:\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    cv2.imwrite(output_path, img)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(f\"Redacted signatures/stamps saved as {output_path}\")"
      ],
      "metadata": {
        "id": "YB-46SY4YIxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_signatures(\"Signature.jpg\")"
      ],
      "metadata": {
        "id": "hlmMvpkRZK1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from pyzbar.pyzbar import decode\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Haar cascade for faces\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "def redact_all(image_path, output_path=\"final_redacted.png\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 1. Face Detection\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    # 2. Signature/Stamp Detection (ink-based)\n",
        "    _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        if 50 < w < 500 and 10 < h < 200:  # heuristic for signatures\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    # 3. QR/Barcode Detection\n",
        "    barcodes = decode(Image.open(image_path))\n",
        "    for bc in barcodes:\n",
        "        (x, y, w, h) = bc.rect\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
        "\n",
        "    # Save + show\n",
        "    cv2.imwrite(output_path, img)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(f\"Redacted image saved as {output_path}\")"
      ],
      "metadata": {
        "id": "coImJbe6ZSjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_faces(\"qr.png\")"
      ],
      "metadata": {
        "id": "8o46NvxoZmbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils libzbar0\n",
        "!pip install pytesseract pdf2image opencv-python PyMuPDF spacy pyzbar Pillow\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "FVDF6fhmZqwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy, re\n",
        "import fitz  # PyMuPDF\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "from pyzbar.pyzbar import decode\n",
        "from PIL import Image\n",
        "\n",
        "# Load NLP model\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "regex_patterns = {\n",
        "    \"PHONE\": r\"\\+?\\d[\\d -]{8,12}\\d\",\n",
        "    \"AADHAAR\": r\"\\d{4}-\\d{4}-\\d{4}\",\n",
        "    \"EMAIL\": r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "}\n",
        "\n",
        "def detect_pii_text(text):\n",
        "    pii = []\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"PERSON\",\"GPE\",\"ORG\",\"DATE\",\"CARDINAL\",\"MONEY\"]:\n",
        "            pii.append(ent.text)\n",
        "    for label, pattern in regex_patterns.items():\n",
        "        pii.extend(re.findall(pattern, text))\n",
        "    return list(set(pii))"
      ],
      "metadata": {
        "id": "iZko955IaNNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "def redact_visual(img_path, out_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Faces\n",
        "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,0),-1)\n",
        "\n",
        "    # Signatures/Stamps\n",
        "    _, thresh = cv2.threshold(gray,120,255,cv2.THRESH_BINARY_INV)\n",
        "    contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in contours:\n",
        "        x,y,w,h=cv2.boundingRect(cnt)\n",
        "        if 50<w<500 and 10<h<200:\n",
        "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,0),-1)\n",
        "\n",
        "    # QR/Barcode\n",
        "    barcodes = decode(Image.open(img_path))\n",
        "    for bc in barcodes:\n",
        "        (x,y,w,h)=bc.rect\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,0),-1)\n",
        "\n",
        "    cv2.imwrite(out_path,img)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "xtP-WZUfaWM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_pdf_full(input_pdf, output_pdf):\n",
        "    doc = fitz.open(input_pdf)\n",
        "    for i, page in enumerate(doc):\n",
        "        # --- Text Redaction ---\n",
        "        text = page.get_text()\n",
        "        pii_list = detect_pii_text(text)\n",
        "        for pii in pii_list:\n",
        "            for area in page.search_for(pii):\n",
        "                page.add_redact_annot(area, fill=(0,0,0))\n",
        "        page.apply_redactions()\n",
        "\n",
        "        # --- Image Redaction ---\n",
        "        images = page.get_images(full=True)\n",
        "        for img_index, img in enumerate(images):\n",
        "            xref = img[0]\n",
        "            base_img = doc.extract_image(xref)\n",
        "            img_bytes = base_img[\"image\"]\n",
        "            ext = base_img[\"ext\"]\n",
        "            img_path = f\"page{i}_img{img_index}.{ext}\"\n",
        "            with open(img_path, \"wb\") as f:\n",
        "                f.write(img_bytes)\n",
        "\n",
        "            # Run visual redaction\n",
        "            redacted_path = f\"redacted_{img_path}\"\n",
        "            redact_visual(img_path, redacted_path)\n",
        "\n",
        "            # Replace in PDF (fix: update_stream instead of update_image)\n",
        "            with open(redacted_path, \"rb\") as f:\n",
        "                doc.update_stream(xref, f.read())\n",
        "\n",
        "    doc.save(output_pdf)\n",
        "    print(f\"‚úÖ Final redacted PDF saved as {output_pdf}\")"
      ],
      "metadata": {
        "id": "xyL_Y5NHaYJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_pdf_full(\"test_doc.pdf\", \"final_redacted_test.pdf\")"
      ],
      "metadata": {
        "id": "FKZ47RwFaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def redact_visual(img_path, out_path, style=\"black\"):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Helper function for region styling\n",
        "    def apply_style(x, y, w, h):\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "        if style == \"black\":\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0,0,0), -1)\n",
        "        elif style == \"blur\":\n",
        "            roi_blur = cv2.GaussianBlur(roi, (51,51), 30)\n",
        "            img[y:y+h, x:x+w] = roi_blur\n",
        "        elif style == \"pseudonym\":\n",
        "            cv2.putText(img, \"XXXX\", (x, y+h//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
        "\n",
        "    # Faces\n",
        "    faces = face_cascade.detectMultiScale(gray,1.1,4)\n",
        "    for (x,y,w,h) in faces:\n",
        "        apply_style(x,y,w,h)\n",
        "\n",
        "    # Signatures\n",
        "    _, thresh = cv2.threshold(gray,120,255,cv2.THRESH_BINARY_INV)\n",
        "    contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in contours:\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        if 50<w<500 and 10<h<200:\n",
        "            apply_style(x,y,w,h)\n",
        "\n",
        "    # QR/Barcodes\n",
        "    barcodes = decode(Image.open(img_path))\n",
        "    for bc in barcodes:\n",
        "        (x,y,w,h) = bc.rect\n",
        "        apply_style(x,y,w,h)\n",
        "\n",
        "    cv2.imwrite(out_path, img)\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "eS_5OlD5afBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_visual(\"Signature.jpg\", \"out_black.png\", style=\"black\")\n",
        "redact_visual(\"Untitled design.jpg\", \"out_blur.png\", style=\"blur\")\n",
        "redact_visual(\"qr.png\", \"out_pseudo.png\", style=\"pseudonym\")"
      ],
      "metadata": {
        "id": "NE9yjbj3bZ9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def redact_pdf_with_log(input_pdf, output_pdf, style=\"black\", log_file=\"audit_log.json\"):\n",
        "    log_data = {\"file\": input_pdf, \"redactions\": []}\n",
        "    doc = fitz.open(input_pdf)\n",
        "\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        pii_list = detect_pii_text(text)\n",
        "\n",
        "        for pii in pii_list:\n",
        "            for area in page.search_for(pii):\n",
        "                page.add_redact_annot(area, fill=(0,0,0))\n",
        "            log_data[\"redactions\"].append({\"page\": i+1, \"type\": \"text\", \"value\": pii})\n",
        "        page.apply_redactions()\n",
        "\n",
        "        images = page.get_images(full=True)\n",
        "        for img_index, img in enumerate(images):\n",
        "            xref = img[0]\n",
        "            base_img = doc.extract_image(xref)\n",
        "            ext = base_img[\"ext\"]\n",
        "            img_path = f\"page{i}_img{img_index}.{ext}\"\n",
        "            with open(img_path,\"wb\") as f:\n",
        "                f.write(base_img[\"image\"])\n",
        "\n",
        "            redacted_path = f\"redacted_{img_path}\"\n",
        "            redact_visual(img_path, redacted_path, style=style)\n",
        "\n",
        "            with open(redacted_path,\"rb\") as f:\n",
        "                doc.update_stream(xref, f.read())\n",
        "\n",
        "            log_data[\"redactions\"].append({\"page\": i+1, \"type\": \"image\", \"action\": style})\n",
        "\n",
        "    doc.save(output_pdf)\n",
        "\n",
        "    with open(log_file,\"w\") as f:\n",
        "        json.dump(log_data,f,indent=2)\n",
        "\n",
        "    print(f\"‚úÖ Saved {output_pdf} and audit log {log_file}\")"
      ],
      "metadata": {
        "id": "Z0vCaeA3bqmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redact_pdf_with_log(\"test_doc.pdf\", \"redacted_with_log.pdf\", style=\"blur\")"
      ],
      "metadata": {
        "id": "o2A_jSX1bznN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tesseract-ocr tesseract-ocr-hin tesseract-ocr-tam\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "lho53FwSb2sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Example Hindi text image\n",
        "hindi_img = Image.new(\"RGB\", (400, 100), (255, 255, 255))\n",
        "import cv2, numpy as np\n",
        "cv2.putText(np.array(hindi_img), \"‡§Ü‡§ß‡§æ‡§∞ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ: ‡•ß‡•®‡•©‡•™-‡•´‡•¨‡•≠‡•Æ-‡•Ø‡•ß‡•®‡•©\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
        "\n",
        "# Run Hindi OCR\n",
        "hindi_text = pytesseract.image_to_string(hindi_img, lang=\"hin\")\n",
        "print(\"Extracted Hindi Text:\", hindi_text)"
      ],
      "metadata": {
        "id": "bUeA1DwRb9PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tamil_text = pytesseract.image_to_string(hindi_img, lang=\"tam\")\n",
        "print(\"Extracted Tamil Text:\", tamil_text)\n"
      ],
      "metadata": {
        "id": "ifOvX-HucAZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex_patterns.update({\n",
        "    \"AADHAAR_HINDI\": r\"[‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø]{4}-[‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø]{4}-[‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø]{4}\"\n",
        "})"
      ],
      "metadata": {
        "id": "dSQaOHcscCFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = {\n",
        "    \"test_doc.pdf\": [\"Rahul Sharma\", \"+91-9876543210\", \"123 MG Road, Bangalore\", \"1234-5678-9123\"]\n",
        "}"
      ],
      "metadata": {
        "id": "8chied5ecEJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_redaction(file, ground_truth_entities):\n",
        "    doc = fitz.open(file)\n",
        "    detected = set()\n",
        "    for page in doc:\n",
        "        text = page.get_text()\n",
        "        detected.update(detect_pii_text(text))\n",
        "\n",
        "    tp = len(set(ground_truth_entities) & detected)\n",
        "    fp = len(detected - set(ground_truth_entities))\n",
        "    fn = len(set(ground_truth_entities) - detected)\n",
        "\n",
        "    precision = tp / (tp+fp) if (tp+fp)>0 else 0\n",
        "    recall = tp / (tp+fn) if (tp+fn)>0 else 0\n",
        "    return {\"precision\": precision, \"recall\": recall, \"tp\": tp, \"fp\": fp, \"fn\": fn}"
      ],
      "metadata": {
        "id": "kkrjNeDkcNNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_redaction(\"test_doc.pdf\", ground_truth[\"test_doc.pdf\"])\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "OyfAH5zjcO89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_pdfs(original, redacted, page_num=0):\n",
        "    pages = convert_from_path(original, dpi=150)\n",
        "    redacted_pages = convert_from_path(redacted, dpi=150)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
        "    axs[0].imshow(pages[page_num]); axs[0].set_title(\"Original\"); axs[0].axis(\"off\")\n",
        "    axs[1].imshow(redacted_pages[page_num]); axs[1].set_title(\"Redacted\"); axs[1].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "compare_pdfs(\"test_doc.pdf\", \"final_redacted_test.pdf\")"
      ],
      "metadata": {
        "id": "CCJ7FCRHcQqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "HKqMQx_CcS5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import fitz\n",
        "import os\n",
        "from tempfile import NamedTemporaryFile\n",
        "\n",
        "st.set_page_config(page_title=\"DeID-Guard\", layout=\"centered\")\n",
        "\n",
        "st.title(\"üõ°Ô∏è DeID-Guard ‚Äì Privacy by Design\")\n",
        "st.write(\"Upload a document and choose how to anonymize sensitive data.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF/Image\", type=[\"pdf\",\"jpg\",\"png\"])\n",
        "style = st.radio(\"Choose Redaction Style\", [\"black\", \"blur\", \"pseudonym\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    st.success(f\"File `{uploaded_file.name}` uploaded successfully!\")\n",
        "\n",
        "    if st.button(\"Run De-identification\"):\n",
        "        input_path = uploaded_file.name\n",
        "        with open(input_path,\"wb\") as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "\n",
        "        output_pdf, log_file = redact_pdf_with_log(input_path, \"redacted_output.pdf\", style=style)\n",
        "\n",
        "        st.success(\"‚úÖ De-identification completed!\")\n",
        "\n",
        "        # Preview first page\n",
        "        pages = convert_from_path(output_pdf, dpi=150)\n",
        "        st.image(pages[0], caption=\"Redacted PDF Preview (Page 1)\", use_container_width=True)\n",
        "\n",
        "        with open(output_pdf,\"rb\") as f:\n",
        "            st.download_button(\"‚¨áÔ∏è Download Redacted PDF\", f, file_name=\"redacted.pdf\")\n",
        "\n",
        "        with open(log_file,\"rb\") as f:\n",
        "            st.download_button(\"‚¨áÔ∏è Download Audit Log (JSON)\", f, file_name=\"audit_log.json\")\n"
      ],
      "metadata": {
        "id": "B8XzWipncaa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "9jxiZX50sYzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501\n",
        "!nohup streamlit run app.py --server.port 8501 &"
      ],
      "metadata": {
        "id": "gcw8euB9wib7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Kill any running ngrok processes\n",
        "for proc in psutil.process_iter(['pid', 'name']):\n",
        "    if proc.info['name'] == 'ngrok':\n",
        "        print(f\"Killing ngrok process with PID: {proc.info['pid']}\")\n",
        "        proc.kill()\n",
        "\n",
        "# Run Streamlit in background\n",
        "os.system(\"nohup streamlit run app.py --server.port 8501 &\")\n",
        "\n",
        "time.sleep(5)  # wait for streamlit\n",
        "\n",
        "# Auth for ngrok\n",
        "ngrok.set_auth_token(\"32YE2dnGk7AkEQ8qbyPF9jrEWDg_7FGuwpYte26gYK9fJut65\")  # replace with your real token\n",
        "\n",
        "# Open tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåê Your DeID-Guard app is live at:\", public_url)"
      ],
      "metadata": {
        "id": "RqK_1Pwbu4ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}